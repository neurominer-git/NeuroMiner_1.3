

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Learning algorithm parameters &#8212; NeuroMiner Manual</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/basic.css" />
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/styles/theme.css" />
    <link rel="stylesheet" type="text/css" href="_static/styles/bootstrap.css" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css" />
    <link rel="stylesheet" type="text/css" href="_static/vendor/fontawesome/6.1.2/css/all.min.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/documentation_options.js"></script>
    <script src="_static/searchtools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/design-tabs.js"></script>
    <script src="_static/language_data.js"></script>
    <script src="_static/copybutton_funcs.js"></script>
    <script src="_static/jquery-3.6.0.js"></script>
    <script src="_static/sphinx-thebe.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore-1.13.1.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js"></script>
    <script src="_static/scripts/bootstrap.js"></script>
    <script src="_static/scripts/pydata-sphinx-theme.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-1F3TPH8HH8"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-1F3TPH8HH8');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '4.2.04_paramtemp_learning_algorithm_parameters';</script>
    <link rel="canonical" href="https://neurominer-git.github.io/NeuroMiner_1.3/4.2.04_paramtemp_learning_algorithm_parameters.html" />
    <link rel="shortcut icon" href="_static/nm_logo2.ico"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Ensemble generation strategies" href="4.2.05_paramtemp_ensemble_generation_strategies.html" />
    <link rel="prev" title="Classification algorithm" href="4.2.03_paramtemp_classification_algorithm.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
    
    
      
    
    
    <img src="_static/nm_logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="_static/nm_logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    NeuroMiner
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">News</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="5.00_1.2_release_notes.html">NeuroMiner 1.2 (09/2023)</a></li>
<li class="toctree-l1"><a class="reference internal" href="0.1_2024_MLSchool.html">Online Machine Learning School 2024</a></li>
<li class="toctree-l1"><a class="reference internal" href="0.1_2023_MLSchool.html">Online Machine Learning School 2023 - Europe</a></li>
<li class="toctree-l1"><a class="reference internal" href="0.1_2023_MLSchool_AsiaPacific.html">Online Machine Learning School 2023 - Asia-Pacific</a></li>
<li class="toctree-l1"><a class="reference internal" href="0.0_previous_MLSchool.html">Past Schools</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Getting started</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="1.0_introduction.html">Introduction</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="license.html">License</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="2.0_prerequisites.html">Suggested Prerequisites</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="3.0_gettingstarted.html">Installation &amp; Configuration</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="3.0.00_macos_users.html">Setting up NeuroMiner on macOS</a></li>
<li class="toctree-l2"><a class="reference internal" href="3.0.01_python_matlab.html">Python integration in MATLAB</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">NeuroMiner interface</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="4.0_mainmenu.html">Main interface overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="4.1_mainmenu_input_data.html">Data entry in NeuroMiner</a></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="4.2_mainmenu_define_parameter_template.html">Define parameter template</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="4.2.00_paramtemp_data_fusion.html">Data Fusion</a></li>
<li class="toctree-l2"><a class="reference internal" href="4.2.01_paramtemp_cv_settings.html">Cross-validation settings</a></li>
<li class="toctree-l2"><a class="reference internal" href="4.2.02_paramtemp_preprocessing_pipeline.html">Preprocessing pipeline</a></li>
<li class="toctree-l2"><a class="reference internal" href="4.2.03_paramtemp_classification_algorithm.html">Classification algorithm</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Learning algorithm parameters</a></li>
<li class="toctree-l2"><a class="reference internal" href="4.2.05_paramtemp_ensemble_generation_strategies.html">Ensemble generation strategies</a></li>
<li class="toctree-l2"><a class="reference internal" href="4.2.06_paramtemp_visualization_options.html">Visualization options</a></li>
<li class="toctree-l2"><a class="reference internal" href="4.2.07_paramtemp_interpretation_options.html">Prediction interpretation options</a></li>
<li class="toctree-l2"><a class="reference internal" href="4.2.08_paramtemp_model_saving_options.html">Model saving options</a></li>
<li class="toctree-l2"><a class="reference internal" href="4.2.09_paramtemp_define_verbosity_level.html">Define verbosity level</a></li>
<li class="toctree-l2"><a class="reference internal" href="4.2.10_paramtemp_inspect_workspace.html">Inspect workspace</a></li>
<li class="toctree-l2"><a class="reference internal" href="4.2.11_paramtemp_save_parameter_template.html">Save parameter template</a></li>
<li class="toctree-l2"><a class="reference internal" href="4.2.12_paramtemp_load_training_template.html">Load training template</a></li>
<li class="toctree-l2"><a class="reference internal" href="4.2.13_paramtemp_multigroup.html">Multi-group analyses</a></li>
<li class="toctree-l2"><a class="reference internal" href="4.2.14_paramtemp_stacking.html">Stacking</a></li>
<li class="toctree-l2"><a class="reference internal" href="4.2.15_paramtemp_different_label.html">Use different label</a></li>
<li class="toctree-l2"><a class="reference internal" href="4.2.16_paramtemp_synthetic_data.html">Synthetic data</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="4.3_mainmenu_initialize_delete_analyses.html">Initialize analyses</a></li>
<li class="toctree-l1"><a class="reference internal" href="4.4_mainmenu_preprocess_features.html">Preprocess features</a></li>
<li class="toctree-l1"><a class="reference internal" href="4.5_mainmenu_train_supervised_classifiers.html">Train supervised classifiers</a></li>
<li class="toctree-l1"><a class="reference internal" href="4.6_mainmenu_visualize_classifiers.html">Visualize classifiers</a></li>
<li class="toctree-l1"><a class="reference internal" href="4.14_mainmenu_interprete_classifiers.html">Interprete predictions</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="4.7_mainmenu_display_training_results.html">Result Viewer</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="4.7.01_mainmenu_display_visualization_results.html">Visualization results</a></li>

<li class="toctree-l2"><a class="reference internal" href="4.7.02_mainmenu_display_interpretation_results.html">ML Interpreter (MLI) results</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="4.8_mainmenu_OOCV_analysis.html">Out of Sample Cross-Validation</a></li>
<li class="toctree-l1"><a class="reference internal" href="4.15_mainmenu_export_model.html">Export model parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="4.9_mainmenu_load_struct.html">Load NeuroMiner structure</a></li>
<li class="toctree-l1"><a class="reference internal" href="4.10_mainmenu_save_struct.html">Save NeuroMiner structure</a></li>
<li class="toctree-l1"><a class="reference internal" href="4.11_mainmenu_change_wd.html">Change working directory</a></li>
<li class="toctree-l1"><a class="reference internal" href="4.12_mainmenu_estimate_sample_size.html">Estimate sample size (simulation tool)</a></li>
<li class="toctree-l1"><a class="reference internal" href="4.13_mainmenu_utilities.html">Utilities</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Parallelization</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="5.01_NM_compilation.html">Parallelization on HPC server - NeuroMiner compilation</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/neurominer-git/NeuroMiner_1.3" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/neurominer-git/NeuroMiner_1.3/issues/new?title=Issue%20on%20page%20%2F4.2.04_paramtemp_learning_algorithm_parameters.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/4.2.04_paramtemp_learning_algorithm_parameters.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Learning algorithm parameters</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#support-vector-machines-libsvm">SUPPORT VECTOR MACHINES (LIBSVM)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#support-vector-machines-liblinear">SUPPORT VECTOR MACHINES (LIBLINEAR)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#glmnet-hastie-s-library-for-lasso-elastic-net-regularized-glms">GLMNET (Hastie’s library for LASSO/Elastic-net regularized GLMs)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#random-forests-sklearn-randomforestclassifier">RANDOM FORESTS (sklearn RandomForestClassifier)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gradient-boosting-sklearn-gradientboostingclassifier">GRADIENT BOOSTING (sklearn GradientBoostingClassifier)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mlp-perceptron-sklearn-mlpclassifier">MLP PERCEPTRON (sklearn MLPClassifier)</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <div class="tex2jax_ignore mathjax_ignore section" id="learning-algorithm-parameters">
<span id="id1"></span><h1>Learning algorithm parameters<a class="headerlink" href="#learning-algorithm-parameters" title="Permalink to this heading">#</a></h1>
<p>Parameters for a learning algorithm determine the way that the model is fitted to the data. A common example is the ”C” or ”slack” parameter for soft margin SVM that defines the penalty associated with misclassifying individuals – i.e., whether the model does not allow any error within the CV1 folds and very tightly fits the decision boundary, or whether it allows errors in order to improve generalizability. Therefore, parameters such as these can greatly affect the model performance and it is common practice in machine learning to optimize the parameters for your specific problem and data.</p>
<p>NeuroMiner was developed in order to optimize performance across pre-defined parameter ranges within the nested cross-validation framework using a gridsearch, which protects against overfitting due to the application of the trained models to held-out data. Default parameter ranges are provided in NeuroMiner based on the literature and empirical testing, but we strongly recommend that the parameters are defined for your study and problem.</p>
<p>As previously stated, NeuroMiner uses a dynamic menu configuration that changes based on previous input. This is also true for the learning algorithm parameters, whereby the menu options will change based on what you have selected in the ”Classification algorithm” section.</p>
<div class="section" id="support-vector-machines-libsvm">
<h2>SUPPORT VECTOR MACHINES (LIBSVM)<a class="headerlink" href="#support-vector-machines-libsvm" title="Permalink to this heading">#</a></h2>
<p>Here we show an example for a RBF-Gaussian kernel SVM classifier with LIBSVM. The options might vary depending on the configurations of the model.</p>
<blockquote>
<div><p>1 | Define Slack/Regularization parameter(s)</p>
<p>2 | Define RBF/Gaussian kernel parameter(s)</p>
<p>3 | Enable regularization of model selection</p>
<p>4 | Criterion for cross-parameter model selection</p>
<p>5 | Define weight (lambda) of SV ratio</p>
<p>6 | Define non-linearity (big gamma) of SV ratio</p>
</div></blockquote>
<blockquote>
<div><p>7 | Specify cross-parameter model selection process</p>
</div></blockquote>
<p><strong>1 | Define Slack/Regularization parameter(s)</strong>
The Slack/Regularization parameter, also known as C parameter, is a hyperparameter specific to SVM. In NeuroMiner, a range of values can be specified here and it will be optimized throughout model training within the defined cross-validation structure.</p>
<p><strong>2 | Define RBF/Gaussian kernel parameter(s)</strong>
See <a class="reference external" href="https://www.csie.ntu.edu.tw/~cjlin/libsvm/faq.html#f410">link</a>.</p>
<p><strong>3 | Enable regularization of model selection</strong>
This option enables the control of selection of models by considering the variability of performance across thre CV1 test folds. This approach aims to improve model selection by factoring in the consistency of performance metrics obtained from cross-validation.</p>
<p><strong>4 | Criterion for cross-parameter model selection</strong>
Criterion used to choose the optimal model when multiple hyperparameters are being tested. The options are model complexity, ensemble diversity, model performance, or complexity and ensemble diversity.</p>
<p><strong>5 | Define weight (lambda) of SV ratio</strong>
The weight controls the trade-off between between maximizing the margin and minimizing the classification errors of the SVM.</p>
<p><strong>6 | Define non-linearity (big gamma) of SV ratio</strong>
Determines the shape of the decision boundary. Higher gammas create a more complex (highly non-linear) decision boundary that can fit intricate patterns in dataThis can be helpful for highly non-linear datasets but might also lead to overfitting.</p>
<p><strong>7 | Specify cross-parameter model selection process</strong>
This option controls the number of models (parameters combination) selected. One optimal model based on the criteria and regularization defined previously or an ensemble of the top performing models
You are given the possibility to select between: (1) select a single optimum parameter node which returns one optimal model based on the criteria, (2) generate cross-node ensemble by aggregating base learners above a predefined percentile which results in an ensemble of the top performing models or (3) automatically determine optimal percentile for optimum cross-node ensemble performance which depends on the regularization.</p>
<div class="section" id="support-vector-machines-liblinear">
<h3>SUPPORT VECTOR MACHINES (LIBLINEAR)<a class="headerlink" href="#support-vector-machines-liblinear" title="Permalink to this heading">#</a></h3>
<p>Here we show an example of a linear SVM using the LIBLINEAR library.</p>
<blockquote>
<div><p>1 | Define Slack/Regularization parameter(s)</p>
<p>2 | Define Weighting exponents</p>
<p>3 | Enable regularization of model selection using CV1 test performance variance</p>
<p>4 | Specify cross-parameter model selection process</p>
</div></blockquote>
<p><strong>1 | Define Slack/Regularization parameter(s)</strong>
The Slack/Regularization parameter, also known as C parameter, is a hyperparameter specific to SVM. In NeuroMiner, a range of values can be specified here and it will be optimized throughout model training within the defined cross-validation structure.</p>
<p><strong>2 | Define Weighting exponents</strong>
Configures the weight applied to weighting the coefficient applied to the samples from different classes in imbalanced data.</p>
<p><strong>3 | Enable regularization of model selection</strong>
This option enables the control of selection of models by considering the variability of performance across thre CV1 test folds. This approach aims to improve model selection by factoring in the consistency of performance metrics obtained from cross-validation.</p>
<p><strong>4 | Specify cross-parameter model selection process</strong>
This option controls the number of models (parameters combination) selected. One optimal model based on the criteria and regularization defined previously or an ensemble of the top performing models
You are given the possibility to select between: (1) select a single optimum parameter node which returns one optimal model based on the criteria, (2) generate cross-node ensemble by aggregating base learners above a predefined percentile which results in an ensemble of the top performing models or (3) automatically determine optimal percentile for optimum cross-node ensemble performance which depends on the regularization.</p>
</div>
<div class="section" id="glmnet-hastie-s-library-for-lasso-elastic-net-regularized-glms">
<h3>GLMNET (Hastie’s library for LASSO/Elastic-net regularized GLMs)<a class="headerlink" href="#glmnet-hastie-s-library-for-lasso-elastic-net-regularized-glms" title="Permalink to this heading">#</a></h3>
<p>The configuration options for the GLMNET models are the following:</p>
<blockquote>
<div><p>1 | Define GLMNET parameters</p>
</div></blockquote>
<p><strong>1 | Define GLMNET parameters</strong>
This option allows the user to access another menu where 5 GLMNET parameters can be configured.</p>
<p>Inside option 1, the following parameters appear:</p>
<blockquote>
<div><p>1 | Define mixing factor (alpha) range (0 =ridge &lt;-&gt; 1 =lasso)</p>
<p>2 | Define minimum lambda range (e.g. if N_cases&gt;N_feats: 0.0001, otherwise 0.01)</p>
<p>3 | Define number of lambda optimization steps</p>
<p>4 | Define maximum number(s) of variables in the model</p>
<p>5 | Standardize input matrix to unit variance prior to training the elastic net</p>
</div></blockquote>
<p><strong>1 | Define mixing factor (alpha) range</strong><br />
Alpha is  the elastic net mixing parameter, with range alpha∈[0,1], alpha=1 is lasso regression (default) and α=0 is ridge regression.</p>
<p><strong>2 | Define minimum lambda range</strong><br />
Specifies the minimum value of lambda for regularization. A smaller value applies lighter regularization, while a larger value applies stronger regularization, particularly useful in high-dimensional settings.</p>
<p><strong>3 | Define number of lambda optimization steps</strong><br />
Determines the number of lambda values over which the model will be optimized. A larger number gives a finer-grained search over the regularization path but increases computation time.</p>
<p><strong>4 | Define maximum number(s) of variables in the model</strong>
Sets a limit on the number of variables that can be selected by the model. This controls the model’s complexity by constraining the number of features it can use.</p>
<p><strong>5 | Standardize input matrix to unit variance prior to training the elastic net</strong>
Specifies whether to standardize the input data before fitting the model. When ‘Yes’, the features are scaled to unit variance.</p>
</div>
<div class="section" id="random-forests-sklearn-randomforestclassifier">
<h3>RANDOM FORESTS (sklearn RandomForestClassifier)<a class="headerlink" href="#random-forests-sklearn-randomforestclassifier" title="Permalink to this heading">#</a></h3>
<p>The configuration options for the RF classifier are originally defined in the scikit-learn documentation of the <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html">RandomForestClassifier</a> class. We will give a brief description of each parameter here.</p>
<blockquote>
<div><p>1 | Define Number of decision trees</p>
<p>2 | Define Maximum number of features</p>
<p>3 | Define Function to measure the quality of a split</p>
<p>4 | Define Maximum depth of the tree</p>
<p>5 | Define Minimum number of samples to split</p>
<p>6 | Define Minimum number of samples to be at a leaf</p>
<p>7 | Define Minimum weighted fraction of the sum total of weights at a leaf</p>
<p>8 | Define Maximum number of leaf nodes</p>
<p>9 | Define Minimum decrease of impurity</p>
<p>10 | Define Bootstrap samples yes/no</p>
<p>11 | Define Out-of-bag samples yes/no</p>
<p>12 | Define Class weights</p>
<p>13 | Define Complexity parameter for Minimal Cost-Complexity Pruning</p>
<p>14 | Define Number of samples to draw from X to train base estimators (if bootstrap)</p>
</div></blockquote>
<p><strong>1 | Define Number of decision trees</strong><br />
Sets the number of decision trees (estimators) to be used in the random forest model. A higher number of trees generally improves accuracy but increases computation time.</p>
<p><strong>2 | Define Maximum number of features</strong><br />
Specifies the maximum number of features to consider when looking for the best split at each node. Common settings include ‘sqrt’ (square root of the total number of features), ‘log2’, or an integer value.</p>
<p><strong>3 | Define Function to measure the quality of a split</strong><br />
Chooses the criterion for splitting nodes in the trees. Options include ‘Gini impurity’, which measures the likelihood of misclassification, or ‘Entropy’, which measures the information gain.</p>
<p><strong>4 | Define Maximum depth of the tree</strong><br />
Limits the maximum depth of each tree in the forest. Setting this prevents trees from growing too deep and potentially overfitting, while ‘No max. depth defined’ allows trees to grow until all leaves are pure or contain fewer than the minimum samples.</p>
<p><strong>5 | Define Minimum number of samples to split</strong><br />
Determines the minimum number of samples required to split an internal node. A higher number can prevent overfitting by requiring larger segments of data to create a split.</p>
<p><strong>6 | Define Minimum number of samples to be at a leaf</strong><br />
Specifies the minimum number of samples required to be at a leaf node. Increasing this value makes the model more conservative and prevents overly specific rules in the trees.</p>
<p><strong>7 | Define Minimum weighted fraction of the sum total of weights at a leaf</strong><br />
Sets the minimum weighted fraction of the input data required to be at a leaf node. This parameter is particularly useful in datasets with varying sample weights.</p>
<p><strong>8 | Define Maximum number of leaf nodes</strong><br />
Limits the maximum number of leaf nodes per tree. A smaller number results in simpler models, while ‘No max. N defined’ allows trees to grow fully based on the other criteria.</p>
<p><strong>9 | Define Minimum decrease of impurity</strong><br />
Specifies the minimum decrease in impurity required for a node to be split. Setting this threshold helps prevent splitting nodes that do not significantly improve the model.</p>
<p><strong>10 | Define Bootstrap samples yes/no</strong><br />
Indicates whether bootstrap samples (random samples with replacement) are used when building trees. ‘Yes’ enables bootstrapping, which is a common approach in random forests.</p>
<p><strong>11 | Define Out-of-bag samples yes/no</strong><br />
Determines whether out-of-bag samples (samples not included in the bootstrap sample) are used to estimate the model’s performance. ‘Yes’ allows for internal performance evaluation without the need for a separate validation set.</p>
<p><strong>12 | Define Class weights</strong><br />
Assigns weights to classes to handle imbalanced datasets. If ‘All equal’, each class is treated equally, but you can adjust weights to give more importance to underrepresented classes.</p>
<p><strong>13 | Define Complexity parameter for Minimal Cost-Complexity Pruning</strong><br />
Specifies the threshold used for pruning the tree by considering the cost complexity. Higher values lead to more aggressive pruning.</p>
<p><strong>14 | Define Number of samples to draw from X to train base estimators (if bootstrap)</strong><br />
Determines the number of samples to draw from the input dataset when bootstrapping is enabled. If set to ‘0’, all samples are used, making it equivalent to no bootstrapping.</p>
</div>
<div class="section" id="gradient-boosting-sklearn-gradientboostingclassifier">
<h3>GRADIENT BOOSTING (sklearn GradientBoostingClassifier)<a class="headerlink" href="#gradient-boosting-sklearn-gradientboostingclassifier" title="Permalink to this heading">#</a></h3>
<p>The configuration options for the Gradient boosting classifier are originally defined in the scikit-learn documentation of the <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html">GradientBoostingClassifier</a> class. We will give a brief description of each configuration parameter included in NeuroMiner here.</p>
<blockquote>
<div><p>1 | Define maximum number of boosting iterations</p>
<p>2 | Select type of loss (exponential/deviance for classification, squared/absolute/huber/quantile for regression)</p>
<p>3 | Define learning rate (0&lt;-&gt;1)</p>
<p>4 | Define subsampling factor (0&lt;-&gt;1)</p>
<p>5 | Define maximum tree depth</p>
</div></blockquote>
<hr class="docutils" />
<p><strong>1 | Define maximum number of boosting iterations</strong><br />
Sets the number of boosting stages (iterations) to be run. More iterations can improve model performance but may also lead to overfitting.</p>
<p><strong>2 | Select type of loss (exponential/deviance for classification, squared/absolute/huber/quantile for regression)</strong><br />
Specifies the loss function used to measure model performance. For classification, options include ‘log_loss’ (deviance), while for regression, options include <code class="docutils literal notranslate"><span class="pre">squared_error</span></code>, <code class="docutils literal notranslate"><span class="pre">absolute_error</span></code>, <code class="docutils literal notranslate"><span class="pre">huber</span></code>, and <code class="docutils literal notranslate"><span class="pre">quantile</span></code>.</p>
<p><strong>3 | Define learning rate (0&lt;-&gt;1)</strong><br />
Sets the step size for each boosting iteration. A smaller learning rate requires more boosting iterations but can lead to a more accurate model.</p>
<p><strong>4 | Define subsampling factor (0&lt;-&gt;1)</strong><br />
Specifies the fraction of samples used for fitting each individual tree. Values less than 1 can help prevent overfitting by introducing randomness.</p>
<p><strong>5 | Define maximum tree depth</strong><br />
Limits the depth of each individual tree in the boosting process. Shallower trees are less likely to overfit, while deeper trees can capture more complex patterns.</p>
</div>
<div class="section" id="mlp-perceptron-sklearn-mlpclassifier">
<h3>MLP PERCEPTRON (sklearn MLPClassifier)<a class="headerlink" href="#mlp-perceptron-sklearn-mlpclassifier" title="Permalink to this heading">#</a></h3>
<p>The configuration options for the MLP classifier are originally defined in the scikit-learn documentation of the <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html">MLPClassifier</a> class. Please refer to the original scikit-learn documentation for an exhaustive definition of each parameter. We will provide a brief description of each parameter here.</p>
<blockquote>
<div><p>1 | Define MLPERC parameters</p>
<p>2 | Enable regularization of model selection using CV1 test performance variance</p>
<p>3 | Specify cross-parameter model selection process</p>
</div></blockquote>
<p><strong>1 | Define MLPERC parameters</strong>
This option allows the user to access another menu where MLP parameters can be configured. By default, NeuroMiner allows to tune 4 MLP parameters (see below). Using expert mode (initialize neurominer using “nm expert”), 21 MLP parameters can be configured.</p>
<p><strong>2 | Enable regularization of model selection</strong>
This option enables the control of selection of models by considering the variability of performance across thre CV1 test folds. This approach aims to improve model selection by factoring in the consistency of performance metrics obtained from cross-validation.</p>
<p><strong>3 | Specify cross-parameter model selection process</strong>
This option controls the number of models (parameters combination) selected. One optimal model based on the criteria and regularization defined previously or an ensemble of the top performing models
You are given the possibility to select between: (1) select a single optimum parameter node which returns one optimal model based on the criteria, (2) generate cross-node ensemble by aggregating base learners above a predefined percentile which results in an ensemble of the top performing models or (3) automatically determine optimal percentile for optimum cross-node ensemble performance which depends on the regularization.</p>
<p>Inside option 1, the following parameters appear:</p>
<blockquote>
<div><p>1 | Define MLP structures: hidden layers (length of row) and sizes (values)</p>
<p>2 | Select activation function</p>
<p>3 | Select solver method</p>
<p>4 | Define alpha parameter</p>
<p>5 | Select batch size (expert mode)</p>
<p>6 | Select learning rate strategy (expert mode)</p>
<p>7 | Define initial learning rate (expert mode)</p>
<p>8 | Define power parameter for learning rate decay (expert mode)</p>
<p>9 | Set maximum number of iterations (expert mode)</p>
<p>10 | Set random seed (expert mode)</p>
<p>11 | Define tolerance for optimization (expert mode)</p>
<p>12 | Use warm start (expert mode)</p>
<p>13 | Set momentum parameter (expert mode)</p>
<p>14 | Use Nesterov’s momentum (expert mode)</p>
<p>15 | Set early stopping (expert mode)</p>
<p>16 | Define validation data fraction (expert mode)</p>
<p>17 | Define beta_1 parameter (expert mode)</p>
<p>18 | Define beta_2 parameter (expert mode)</p>
<p>19 | Define epsilon parameter for numerical stability (expert mode)</p>
<p>20 | Set number of iterations with no improvement before stopping (expert mode)</p>
<p>21 | Set maximum function evaluations (expert mode)</p>
</div></blockquote>
<hr class="docutils" />
<p><strong>1 | Define MLP structures: hidden layers (length of row) and sizes (values)</strong><br />
Specifies the architecture(s) of the neural network including the number and size of hidden layers. Each row of the defined matrix will be used as a different network architecture.
For example, ‘[100 100; 200 100]’ will train two neural networks, one with a structure of 100x100 (two hidden layers, each with 100 neurons) and 200x100 (two hidden layers, the first one with 200 neurons and the second one with 100 neurons). If the user needs to define structures with different number of hidden layers, set layer sizes as ‘0’. For example, If testing a 100x100x100 and 100x100, input the following: ‘[100, 100, 100; 100,100, 0]’.</p>
<p><strong>2 | Select activation function</strong><br />
Chooses the activation function used in the neurons. Common options include ‘relu’ (Rectified Linear Unit), ‘tanh’, and ‘sigmoid’.</p>
<p><strong>3 | Select solver method</strong><br />
Determines the optimization algorithm used for training. Options include ‘adam’ (Adaptive Moment Estimation), ‘sgd’ (Stochastic Gradient Descent), and ‘lbfgs’ (Limited-memory Broyden-Fletcher-Goldfarb-Shanno).</p>
<p><strong>4 | Define alpha parameter</strong><br />
Sets the regularization strength to prevent overfitting. A higher ‘alpha’ value increases regularization, helping to control model complexity.</p>
<p><strong>5 | Select batch size</strong><br />
Specifies the number of samples used in each iteration of training. Options include ‘auto’ (which chooses a default value) or a specific integer value.</p>
<p><strong>6 | Select learning rate strategy</strong><br />
Defines the learning rate schedule. Options include ‘constant’ (fixed learning rate), ‘invscaling’ (decreases learning rate as ‘1 / pow(t, power_t)’), and ‘adaptive’ (learning rate adapts based on performance).</p>
<p><strong>7 | Define initial learning rate</strong><br />
Sets the starting learning rate for the training process. This parameter controls the step size during gradient descent.</p>
<p><strong>8 | Define power parameter for learning rate decay</strong><br />
Specifies the power of the inverse scaling learning rate decay. Used when ‘learning_rate’ is set to ‘invscaling’.</p>
<p><strong>9 | Set maximum number of iterations</strong><br />
Limits the number of iterations for training. This parameter helps control the time and resources spent on training.</p>
<p><strong>10 | Set random seed</strong><br />
Specifies the seed for the random number generator to ensure reproducibility of results.</p>
<p><strong>11 | Define tolerance for optimization</strong><br />
Sets the tolerance for stopping criteria. Training will stop when the improvement of the optimization is less than this tolerance.</p>
<p><strong>12 | Use warm start</strong><br />
Indicates whether to reuse the solution of the previous call to fit and add more estimators. Setting this to ‘yes’ allows incremental training.</p>
<p><strong>13 | Set momentum parameter</strong><br />
Specifies the momentum for the ‘sgd’ solver. Momentum helps accelerate convergence and smooth out training dynamics.</p>
<p><strong>14 | Use Nesterov’s momentum</strong><br />
Enables or disables Nesterov’s Accelerated Gradient, which improves the convergence speed by considering the gradient of the anticipated future position.</p>
<p><strong>15 | Set early stopping</strong><br />
Determines whether to use early stopping to halt training when the validation score is not improving. This helps prevent overfitting.</p>
<p><strong>16 | Define validation data fraction</strong><br />
Sets the fraction of training data used for validation in early stopping. This helps monitor performance during training.</p>
<p><strong>17 | Define beta_1 parameter</strong><br />
Specifies the exponential decay rate for the first moment estimates in the ‘adam’ optimizer. Typically set to a value like ‘0.9’.</p>
<p><strong>18 | Define beta_2 parameter</strong><br />
Specifies the exponential decay rate for the second moment estimates in the ‘adam’ optimizer. Typically set to a value like ‘0.999’.</p>
<p><strong>19 | Define epsilon parameter for numerical stability</strong><br />
Sets a small constant added to prevent division by zero in the ‘adam’ optimizer and other algorithms.</p>
<p><strong>20 | Set number of iterations with no improvement before stopping</strong><br />
Specifies the number of iterations with no improvement in the validation score before stopping the training (early stopping).</p>
<p><strong>21 | Set maximum function evaluations</strong><br />
Limits the number of function evaluations during the optimization process. This helps control the computational cost of training.</p>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="4.2.03_paramtemp_classification_algorithm.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Classification algorithm</p>
      </div>
    </a>
    <a class="right-next"
       href="4.2.05_paramtemp_ensemble_generation_strategies.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Ensemble generation strategies</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#support-vector-machines-libsvm">SUPPORT VECTOR MACHINES (LIBSVM)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#support-vector-machines-liblinear">SUPPORT VECTOR MACHINES (LIBLINEAR)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#glmnet-hastie-s-library-for-lasso-elastic-net-regularized-glms">GLMNET (Hastie’s library for LASSO/Elastic-net regularized GLMs)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#random-forests-sklearn-randomforestclassifier">RANDOM FORESTS (sklearn RandomForestClassifier)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gradient-boosting-sklearn-gradientboostingclassifier">GRADIENT BOOSTING (sklearn GradientBoostingClassifier)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mlp-perceptron-sklearn-mlpclassifier">MLP PERCEPTRON (sklearn MLPClassifier)</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By <a href="https://www.lmu-klinikum.de/psychiatrie-und-psychotherapie/forschung-research/working-groups/precision-psychiatry/7ef67d79b4ad4804">Section for Precision Psychiatry, Ludwig-Maximilian-University Munich</a> / <a href="https://www.psych.mpg.de/2571270/precision-psychiatry">Precision Psychiatry Group, Max Planck Institute of Psychiatry</a>
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>