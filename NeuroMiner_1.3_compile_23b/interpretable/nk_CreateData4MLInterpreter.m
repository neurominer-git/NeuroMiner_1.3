function IN = nk_CreateData4MLInterpreter(MLI, RandFeats, Tr, Ts, covars, IN, nx, curclass)
% nk_CreateData4MLInterpreter - Prepares input data for machine learning interpreters
%
% Syntax:
%   IN = nk_CreateData4MLInterpreter(MLI, RandFeats, Tr, Ts, covars, IN, nx, curclass)
%
% Description:
%   The function `nk_CreateData4MLInterpreter` prepares the input data structure 
%   `IN` necessary for machine learning interpreters based on different methods 
%   (e.g., 'posneg', 'median', 'medianflip', 'random', 'shapley'). It takes into 
%   account random feature selection, covariates, and class-specific information 
%   to generate modified datasets that can be used for interpreting machine 
%   learning models. The function handles various preprocessing tasks such as 
%   smoothing, permutation-based adjustments, and data fusion.
%
% Input Arguments:
%   MLI       - Structure containing the machine learning interpreter's configuration, 
%               including the method of interpretation, number of permutations, 
%               and other relevant settings.
%   RandFeats - Matrix or cell array of indices representing randomly selected features.
%   Tr        - Matrix or cell array of training data.
%   Ts        - Matrix or cell array of test data.
%   covars    - Matrix of covariates to be included in the model.
%   IN        - Input structure that holds various datasets and preprocessing flags.
%   nx        - Index representing the current modality or dataset being processed.
%   curclass  - Index or identifier of the current class being analyzed.
%
% Output:
%   IN        - The input structure `IN` is returned with updated fields, including 
%               the prepared datasets for machine learning interpretation, as well 
%               as information on the features used in the process.
%
% Notes:
%   - The function supports different interpretation methods, each of which modifies 
%     the input data in distinct ways, depending on the method specified in `MLI.method`.
%   - For the 'posneg' method, the function creates positive and negative instances 
%     by adjusting feature values based on specified thresholds.
%   - For 'median', 'medianflip', and 'random' methods, the function generates new data 
%     instances based on median values or random selection.
%   - The 'shapley' method is used to create Shapley value-based input datasets.
%   - If the input data has been smoothed, this is accounted for in the preprocessing steps.
%
% Subfunctions:
%   1. CreateData4MLInterpreterPosNeg - Generates positive and negative instances for 'posneg' method.
%   2. CreateData4MLInterpreterMedFlipRand - Handles 'median', 'medianflip', and 'random' methods.
%   3. CreateData4MLInterpreterShapley - Prepares data for Shapley value-based interpretation.
%
% Subfunction Descriptions:
%
%   1. CreateData4MLInterpreterPosNeg:
%      This subfunction generates positive and negative instances of the data based on 
%      specified thresholds. It adjusts the selected features (as indicated by `MapIdx`) 
%      by setting them to upper and lower threshold values computed from the training data. 
%      The subfunction also handles permutations, applying random feature selections across 
%      the training data and storing the results in the output structure.
%
%      Input Arguments:
%        IN      - Input structure with preprocessing and threshold settings.
%        RandFeats - Matrix of random feature selections.
%        Tr      - Training data matrix.
%        Ts      - Test data matrix.
%        MapIdx  - Logical vector indicating which features to modify.
%        fMapIdx - Indices of the features selected by `MapIdx`.
%        nperms  - Number of permutations to apply.
%        n       - Number of features selected by `MapIdx`.
%
%      Output:
%        P       - Matrix of positive instances generated by setting features to upper thresholds.
%        N       - Matrix of negative instances generated by setting features to lower thresholds.
%        I       - Logical matrix indicating which features were modified in each permutation.
%
%   2. CreateData4MLInterpreterMedFlipRand:
%      This subfunction prepares data for the 'median', 'medianflip', and 'random' methods. 
%      Depending on the method, it either sets the selected features to their median values 
%      (for 'median') or modifies the values based on percentile flips (for 'medianflip'). 
%      The 'random' method selects random values for the features from the training data.
%      The subfunction handles the permutations and ensures that the modified instances are 
%      stored appropriately.
%
%      Input Arguments:
%        IN      - Input structure with preprocessing settings.
%        RandFeats - Matrix of random feature selections.
%        Tr      - Training data matrix.
%        Ts      - Test data matrix.
%        MapIdx  - Logical vector indicating which features to modify.
%        fMapIdx - Indices of the features selected by `MapIdx`.
%        nperms  - Number of permutations to apply.
%        n       - Number of features selected by `MapIdx`.
%        method  - String specifying the interpretation method ('median', 'medianflip', 'random').
%
%      Output:
%        M       - Matrix of modified instances based on the selected method.
%        I       - Logical matrix indicating which features were modified in each permutation.
%
%      Method Details:
%      - 'median': Sets the selected features to the median value computed from the training data.
%      - 'medianflip': Flips the percentile values of the features around the median. 
%        For instance, a feature value at the 30th percentile is moved to the 70th percentile, 
%        and vice versa. This is done to explore the effect of feature inversion on the model's 
%        prediction.
%      - 'random': Randomly selects a value for each feature from the corresponding feature 
%        distribution in the training data.
%
%   3. CreateData4MLInterpreterShapley:
%      This subfunction prepares data for Shapley value-based interpretation. It generates 
%      multiple permutations of the input data where selected features are either taken from 
%      the test data or replaced with corresponding features from the training data. This 
%      allows for the computation of Shapley values, which quantify the contribution of each 
%      feature to the model's prediction.
%
%      Input Arguments:
%        RandFeats - Matrix of random feature selections.
%        Tr        - Training data matrix.
%        Ts        - Test data matrix.
%        nperms    - Number of permutations to apply.
%
%      Output:
%        M_all     - 3D matrix containing all permutations of the modified instances for each 
%                    observation in the training data.
%
% =========================================================================
% (c) Nikolaos Koutsouleris, 08/2024

if isfield(IN,'issmoothed') && IN.issmoothed
    sstr = 's'; smoothfl = true;
else
    sstr = ''; smoothfl = false;
end

if IN.oocvflag
    Yocvstr = [sstr 'Yocv2'];
else
    Yocvstr = [sstr 'Yocv'];
end
Ystr = [sstr 'Y'];

method = MLI.method;
nperms = MLI.nperms;

if ~isempty(covars) && nx == 1
    switch method
        case 'posneg'
            IN.covars_rep{1} = repmat(covars,nperms,1);
            IN.covars_rep{2} = repmat(covars,nperms,1);
        case {'median','medianflip','medianmirror','random','shapley'}
            IN.covars_rep = repmat(covars,nperms,1);
    end
end

% MapIdx can be the full feature space or a selection based on the CVR and
% sign-based consistency signature chosen by the user. MapIdx is a logical
% vector indicating which variables should be used
MapIdx = MLI.Modality{nx}.MAP.mapidx{curclass}; 
fMapIdx = find(MapIdx);
n = sum(MapIdx);

switch method

    case 'posneg'
        
        if smoothfl
            sn = numel(IN.X(nx).(Ystr){curclass});
            IN.X(nx).(Yocvstr){curclass} = cell(sn,1);
            for q=1:sn
                [P, N, I] = CreateData4MLInterpreterPosNeg(IN, RandFeats, Tr{q}, Ts{q}, MapIdx, fMapIdx, nperms, n);
                IN.X(nx).(Yocvstr){curclass}{q}{1} = P;
                IN.X(nx).(Yocvstr){curclass}{q}{2} = N;
            end
        else
            [P, N, I] = CreateData4MLInterpreterPosNeg(IN, RandFeats, Tr, Ts, MapIdx, fMapIdx, nperms, n);
            IN.X(nx).(Yocvstr){1} = P;
            IN.X(nx).(Yocvstr){2} = N;
        end
        IN.X(nx).I = I;IN.X(nx).I = I;

    case {'median','medianflip','medianmirror','random'}
        
        if smoothfl
            sn = numel(IN.X(nx).(Ystr){curclass});
            IN.X(nx).(Yocvstr){curclass} = cell(sn,1);
            for q=1:sn
               [ M, I ] = CreateData4MLInterpreterMedFlipRand(IN, RandFeats, Tr{q}, Ts{q}, MapIdx, fMapIdx, nperms, n, method);
               IN.X(nx).(Yocvstr){curclass}{q} = M;
            end
            IN.X(nx).I = I;
        else
            [ IN.X(nx).(Yocvstr) , IN.X(nx).I ] = CreateData4MLInterpreterMedFlipRand(IN, RandFeats, Tr, Ts, MapIdx, fMapIdx, nperms, n, method);
        end
        
    case 'shapley'
        
        if smoothfl
            sn = numel(IN.X(nx).(Ystr){curclass});
            IN.X(nx).(Yocvstr){curclass} = cell(sn,1);
            for q=1:sn
                IN.X(nx).(Yocvstr){curclass}{q} = CreateData4MLInterpreterShapley(RandFeats, Tr{q}, Ts{q}, nperms, MLI.frac);
            end
        else
            IN.X(nx).(Yocvstr) = CreateData4MLInterpreterShapley(RandFeats, Tr, Ts, nperms, MLI.frac);
        end
        IN.X(nx).I = RandFeats;

end

function [P, N, I] = CreateData4MLInterpreterPosNeg(IN, RandFeats, Tr, Ts, MapIdx, fMapIdx, nperms, n)

% Determine extremes of the distribution
upper = prctile(Tr(:,MapIdx), IN.MLI.upper_thresh);
lower = prctile(Tr(:,MapIdx), IN.MLI.lower_thresh);
                
if ~isinf(nperms)

    P = repmat(Ts, nperms, 1);
    N = repmat(Ts, nperms, 1);
    I = false(nperms, size(Tr,2));
            
    % Create modified instances of case
    for i=1:nperms
        
        % RandFeats is a random selection index to variables in MapIdx.
        % It can be selected by randomly indexing the original
        % input space variables or by using an atlas scheme that
        % groups input spaces variables together.
        % Select subsample of features by combining MapIdx and
        % current row of RandFeats. 

        rIdx = RandFeats(i,:);

        P(i, fMapIdx(rIdx)) = upper(rIdx); 
        N(i, fMapIdx(rIdx)) = lower(rIdx);
        I(i, fMapIdx(rIdx)) = true;
    end
else
    I = false(MLI.max_iter, size(Tr,2)); iter = 1; completed = false;
    while iter <= MLI.max_iter
        I(iter, MapIdx(RandFeats(iter,:))) = true;
        if sum( sum(I(1:iter,:)) >= MLI.n_visited ) == n
            completed = true;
            break
        end
        iter=iter+1;
    end
    if ~completed
        warning('\n Not all features underwent the predefined amount of %g modifications after %g iterations.', IN.n_visited, IN.max_iter);
    else
        I(iter,:)=[];
        iter=iter-1;
    end
    P = repmat(Ts, iter, 1);
    N = repmat(Ts, iter, 1);
    for i=1:iter
        P(i, I(i,:)) = upper(I(i,:)); 
        N(i, I(i,:)) = lower(I(i,:));
    end
end

function [M, I] = CreateData4MLInterpreterMedFlipRand(IN, RandFeats, Tr, Ts, MapIdx, fMapIdx, nperms, n, method)

switch method
    case 'median'
        medi = prctile(Tr(:,MapIdx), 50);
    case 'medianflip'
        centiles = nk_ComputePercentiles(Tr(:,MapIdx), Ts(:,MapIdx),'inverse');
        idxU = centiles>50;
        idxL = centiles<=50;
        centiles(idxU) = centiles(idxU) - 50;
        centiles(idxL) = centiles(idxL) + 50;
        medi = nk_ComputePercentiles(Tr(:,MapIdx), centiles, 'normal');
    case 'medianmirror'
        centiles = 100-nk_ComputePercentiles(Tr(:,MapIdx), Ts(:,MapIdx),'inverse');
        medi = nk_ComputePercentiles(Tr(:,MapIdx), centiles, 'normal');
    case 'random'
        U = nk_CountUniques(Tr);
        medi = zeros(1,n);
        
end
if ~isinf(nperms)

    M = repmat(Ts, nperms, 1);
    I = false(nperms, size(Tr,2));
    
    % Create modified instances of case
    for i=1:nperms
        if isequal(method, 'random')
            %AW: for each feature select randomly a value from the training sample
            for j=1:n, medi(j) = U.UX{j}(randi(numel(U.UX{j}))); end
        end
        rIdx = RandFeats(i,:);
        M(i, fMapIdx(rIdx)) = medi(rIdx); 
        I(i, fMapIdx(rIdx)) = true;
    end
else
    I = false( MLI.max_iter, size(Tr,2) ); iter = 1; completed = false;
    while iter <= MLI.max_iter
        I(iter, MapIdx(RandFeats(iter,:))) = true;
        if sum( sum(I(1:iter,:)) >= MLI.n_visited ) == n
            completed = true;
            break
        end
        iter=iter+1;
    end
    if ~completed
        warning('\n Not all features underwent the predefined amount of %g modifications after %g iterations.', IN.MLI.n_visited, IN.MLI.max_iter);
    else
        I(iter,:)=[];
        iter=iter-1;
    end
    M = repmat(Ts, iter, 1);
    for i=1:iter
        %AW: moved here from line 100 to make sure that the same
        %feature is not always replaced by the same random value
        if isequal(method, 'random')
            %AW: for each feature select randomly a value from the training sample
            for j=1:n, medi(j) = U.UX{j}(randi(numel(U.UX{j}))); end
        end
        M(i, I(i,:)) = medi(I(i,:)); 
    end
end

function M_all = CreateData4MLInterpreterShapley(RandFeats, Tr, Ts, nperms, frac)

% Determine the number of training instances to select (e.g. 10% of total)
% to make this computationally feasible in high-dimensional problems
numTrainingInstances = round(frac * size(Tr, 1));

% Randomly select 10% of training instances
selectedIndices = randperm(size(Tr, 1), numTrainingInstances);
selectedTr = Tr(selectedIndices, :);

M = repmat(Ts,size(RandFeats,1),1); %Q
MZ = M(RandFeats); %QZ
M_all = zeros(size(M,1),size(M,2),size(Tr,1));
% Possible improvement: select randomly a subset of training cases to speed
%-up computations.
for obsidx = 1:numTrainingInstances
    %this is the other way round than for method "random",
    %i.e. where the values were modified which were true in
    %RandFeats
    Xprime = repmat(selectedTr(obsidx,:),size(RandFeats,1),1);
    % where a predictor is chosen, take its value from Q => Q(Z) must survive
    % where it is not chosen, take its value from X => X(~Z) must survive
    Xprime(RandFeats) = MZ;
    M_all(:,:,obsidx) = Xprime;
end

%IN.X.Yocv = modified data; IN.X.I = RandFeats -> coalition matrix
